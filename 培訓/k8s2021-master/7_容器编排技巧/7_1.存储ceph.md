### 下载并上传相应镜像 (任何一个节点，但是需要docker login harbor.qytanghost.com)
```shell script
docker pull ceph/ceph:v14.2.10
docker tag ceph/ceph:v14.2.10 harbor.qytanghost.com/public/ceph:v14.2.10
docker push harbor.qytanghost.com/public/ceph:v14.2.10

docker pull rook/ceph:v1.3.11
docker tag rook/ceph:v1.3.11 harbor.qytanghost.com/public/ceph:v1.3.11
docker push harbor.qytanghost.com/public/ceph:v1.3.11

docker pull quay.io/k8scsi/csi-attacher:v2.1.0
docker tag quay.io/k8scsi/csi-attacher:v2.1.0 harbor.qytanghost.com/public/csi-attacher:v2.1.0 
docker push harbor.qytanghost.com/public/csi-attacher:v2.1.0 

docker pull quay.io/k8scsi/csi-provisioner:v1.4.0
docker tag quay.io/k8scsi/csi-provisioner:v1.4.0 harbor.qytanghost.com/public/csi-provisioner:v1.4.0
docker push harbor.qytanghost.com/public/csi-provisioner:v1.4.0

docker pull quay.io/k8scsi/csi-node-driver-registrar:v1.2.0
docker tag quay.io/k8scsi/csi-node-driver-registrar:v1.2.0 harbor.qytanghost.com/public/csi-node-driver-registrar:v1.2.0
docker push harbor.qytanghost.com/public/csi-node-driver-registrar:v1.2.0

docker pull quay.io/k8scsi/csi-resizer:v0.4.0
docker tag quay.io/k8scsi/csi-resizer:v0.4.0 harbor.qytanghost.com/public/csi-resizer:v0.4.0
docker push harbor.qytanghost.com/public/csi-resizer:v0.4.0

docker pull quay.io/k8scsi/csi-snapshotter:v1.2.2
docker tag quay.io/k8scsi/csi-snapshotter:v1.2.2 harbor.qytanghost.com/public/csi-snapshotter:v1.2.2
docker push harbor.qytanghost.com/public/csi-snapshotter:v1.2.2

docker pull quay.io/cephcsi/cephcsi:v2.1.2
docker tag quay.io/cephcsi/cephcsi:v2.1.2 harbor.qytanghost.com/public/cephcsi:v2.1.2
docker push harbor.qytanghost.com/public/cephcsi:v2.1.2

```

----------------------------------注意此处切换设备--------------------------------------

### 在每一个计算节点都额外挂三个500G硬盘 (每一个计算节点)
[root@node01 ~]# lsblk -f
NAME        FSTYPE      LABEL UUID                                   MOUNTPOINT
sda
├─sda1      vfat              F509-C29D                              /boot/efi
├─sda2      xfs               a62600d5-73ad-4888-ae5c-0409c2f9c6f6   /boot
└─sda3      LVM2_member       KassRQ-uHpW-tAcZ-MgzB-KgdW-hAil-0udMli
  ├─cs-root xfs               edec260a-02c5-4571-ac7d-6e1796d180dc   /
  ├─cs-swap swap              c97119b0-528e-4353-b54a-ea92d3d3d7b4   [SWAP]
  └─cs-home xfs               8caac99a-e778-486a-896a-0cf4716e93ec   /home
sdb ### 没有FSTYPE信息
sdc ### 没有FSTYPE信息
sdd ### 没有FSTYPE信息
sr0

----------------------------------注意此处切换设备--------------------------------------

### Github, 与配置文件下载路径
https://github.com/rook/rook
https://github.com/rook/rook/tree/master/cluster/examples/kubernetes/ceph

### 应用资源配置清单，配置基础信息 (任何一个Master)
```shell script
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/common.yaml
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/operator.yaml

```

### 资源配置清单注意事项
配置 ROOK_CSI_KUBELET_DIR_PATH: "/data/kubelet" (kubelet的主目录)
--root-dir /data/kubelet (查看kubelet启动脚本)

修改镜像
ROOK_CSI_CEPH_IMAGE: "harbor.qytanghost.com/public/cephcsi:v2.1.2"
ROOK_CSI_REGISTRAR_IMAGE: "harbor.qytanghost.com/public/csi-node-driver-registrar:v1.2.0"
ROOK_CSI_RESIZER_IMAGE: "harbor.qytanghost.com/public/csi-resizer:v0.4.0"
ROOK_CSI_PROVISIONER_IMAGE: "harbor.qytanghost.com/public/csi-provisioner:v1.4.0"
ROOK_CSI_SNAPSHOTTER_IMAGE: "harbor.qytanghost.com/public/csi-snapshotter:v1.2.2"
ROOK_CSI_ATTACHER_IMAGE: "harbor.qytanghost.com/public/csi-attacher:v2.1.0 "

### 确保状态, 然后继续, 一定不要急 (任何一个Master)
[root@master01 ~]# kubectl get pod -n rook-ceph
NAME                                 READY   STATUS    RESTARTS   AGE
rook-ceph-operator-949bc498d-97qkx   1/1     Running   0          3m42s
rook-discover-gxzh8                  1/1     Running   0          2m49s
rook-discover-mk92z                  1/1     Running   0          2m49s
rook-discover-tjp4g                  1/1     Running   0          2m49s

### 可以考虑使用watch (任何一个Master)
```shell
watch kubectl get pod -n rook-ceph

```

#### 创建集群(任何一个Master)
```shell
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/cluster.yaml

```

### 集群资源配置清单注意事项
修改镜像
image: "harbor.qytanghost.com/public/ceph:v14.2.10"

定义了节点与硬盘
    nodes:
    - name: "node01.qytanghost.com"
      devices:
      - name: "sdb"
      - name: "sdc"
      - name: "sdd"
    - name: "node02.qytanghost.com"
      devices:
      - name: "sdb"
      - name: "sdc"
      - name: "sdd"
    - name: "node03.qytanghost.com"
      devices:
      - name: "sdb"
      - name: "sdc"
      - name: "sdd"

### 一定要看到下面的效果才继续, 一定不要急（差不多第7分钟开始初始化硬盘）(任何一个Master)
### 注意一共 24个 + 所有主机用于ceph硬盘的数量(rook-ceph-osd-x-xxxx)! 数量一定要够 （本次实验需要33个）(任何一个Master)
[root@master01 ~]# kubectl get pod -n rook-ceph
NAME                                                              READY   STATUS        RESTARTS   AGE
csi-cephfsplugin-grfxt                                            3/3     Running       0          7m59s
csi-cephfsplugin-provisioner-665f5db75f-grt6q                     5/5     Running       0          7m59s
csi-cephfsplugin-provisioner-665f5db75f-mdjbt                     5/5     Running       0          7m59s
csi-cephfsplugin-stfw4                                            3/3     Running       0          7m59s
csi-cephfsplugin-vrcqg                                            3/3     Running       0          7m59s
csi-rbdplugin-7lvb7                                               3/3     Running       0          8m
csi-rbdplugin-lchr5                                               3/3     Running       0          8m
csi-rbdplugin-provisioner-b75d8ccc5-6kdg7                         6/6     Running       0          8m
csi-rbdplugin-provisioner-b75d8ccc5-s2wfn                         6/6     Running       0          8m
csi-rbdplugin-x8b6p                                               3/3     Running       0          8m
rook-ceph-crashcollector-node01.qytanghost.com-566cf546-l5k6d     1/1     Running       0          27s
rook-ceph-crashcollector-node02.qytanghost.com-68b486b689-4pfk9   1/1     Running       0          5m55s
rook-ceph-crashcollector-node03.qytanghost.com-6565b89996-zblc9   1/1     Running       0          6m12s
rook-ceph-mgr-a-5c46946fb6-4krp6                                  1/1     Running       0          3m47s
rook-ceph-mon-a-75bc89db48-55tsl                                  1/1     Running       0          6m12s
rook-ceph-mon-b-6878dcd87-bn6s5                                   1/1     Running       0          5m56s
rook-ceph-mon-c-5b975b65d-fw796                                   1/1     Running       0          4m58s
rook-ceph-operator-949bc498d-97qkx                                1/1     Running       0          14m
rook-ceph-osd-0-5b9b4f9cc-6svgc                                   1/1     Running       0          51s
rook-ceph-osd-1-748569f877-sbn45                                  1/1     Running       0          35s
rook-ceph-osd-2-84dff4fc65-h6tr8                                  1/1     Running       0          27s
rook-ceph-osd-3-8595dfc847-9p6vn                                  1/1     Running       0          50s
rook-ceph-osd-4-6b57887c7f-wqr56                                  1/1     Running       0          32s
rook-ceph-osd-5-6bc9f845-hnbkd                                    1/1     Running       0          25s
rook-ceph-osd-6-7dbb468b98-4r5fg                                  1/1     Running       0          49s
rook-ceph-osd-7-54b5dd98c-slrdv                                   1/1     Running       0          30s
rook-ceph-osd-8-67678b8c76-hnssq                                  1/1     Running       0          22s
rook-ceph-osd-prepare-node01.qytanghost.com-6wgt7                 0/1     Completed     0          3m46s
rook-ceph-osd-prepare-node02.qytanghost.com-jt4zb                 0/1     Completed     0          3m46s
rook-ceph-osd-prepare-node03.qytanghost.com-wfcqt                 0/1     Completed     0          3m45s
rook-discover-gxzh8                                               1/1     Running       0          13m
rook-discover-mk92z                                               1/1     Running       0          13m
rook-discover-tjp4g                                               1/1     Running       0          13m

### 创建文件系统 (任何一个Master)
```shell script
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/filesystem.yaml

```

### 创建存储类 (任何一个Master)
```shell script
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/storageclass.yaml

```

### 创建pvc (任何一个Master)
```shell script
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/qytang-pvc.yaml

````

# 一定要看到下面的结果再继续, 一定不要急 (任何一个Master)
[root@master01 ~]# kubectl get pvc
NAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
qytang-pvc   Bound    pvc-76536de9-8a58-4d64-85cc-b885a49348c8   1Gi        RWO            rook-cephfs    6m10s

### 创建dp, 使用ceph的存储 (任何一个Master)
```shell script
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/nginx-curl-ceph-dp.yaml

```

### 查看pod(任何一个Master)
[root@master01 ~]# kubectl get pod -l "app=nginx-curl-ceph-dp"
NAME                                  READY   STATUS    RESTARTS   AGE
nginx-curl-ceph-dp-7c8589f9bc-hggcb   1/1     Running   0          31s

### 进入容器创建文件index.html(任何一个Master)
[root@master01 ~]# kubectl exec -it $(kubectl get pod -l "app=nginx-curl-ceph-dp" -o jsonpath='{.items[0].metadata.name}') -- /bin/bash
[root@nginx-curl-ceph-dp-7c8589f9bc-b5rc6 /]# cd /usr/share/nginx/html/
[root@nginx-curl-ceph-dp-7c8589f9bc-b5rc6 html]# vi index.html

<h1>test</h1>

----------------------------------注意此处切换设备--------------------------------------

### 配置DNS (DNSCA)
```shell script
cat > /var/named/qytangk8s.com.zone <<'EOF'
$ORIGIN qytangk8s.com.
$TTL 600    ;   10 minutes
@       IN SOA  dnsca.qytangk8s.com. dnsadmin.qytangk8s.com. (
                                        2020090901      ; serial
                                        10800           ; refresh (3 hours)
                                        900             ; retry (15 minutes)
                                        604800          ; expire (1 week)
                                        86400           ; minimum (1 day)
                                        )
        NS      dnsca.qytangk8s.com.
$TTL 60    ;   1 minute
dnsca                        A   10.1.1.219
traefik                      A   10.1.1.10
qyt-lb-ds                    A   10.1.1.10
qyt-lb-dp                    A   10.1.1.10
k8sdashboard                 A   10.1.1.10
metricsserver                A   10.1.1.10
nginx-configmap              A   10.1.1.10
nginx-ceph                   A   10.1.1.10
EOF

systemctl restart named

```

----------------------------------注意此处切换设备--------------------------------------

### 网页访问https://nginx-ceph.qytangk8s.com/ (mgmtwin7)

----------------------------------注意此处切换设备--------------------------------------

### 删除pod 和 删除deploy, 文件依然存在 (任何一个Master)

### 如果希望删除文件, 就需要删除pvc(先删除调用pvc的deploy) (任何一个Master)

### 创建share pvc (任何一个Master)
```shell script
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/qytang-pvc-share.yaml

```

### 一定要看到下面的结果再继续, 一定不要急 (任何一个Master)
[root@master01 ~]# kubectl get pvc
NAME               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
qytang-pvc         Bound    pvc-76536de9-8a58-4d64-85cc-b885a49348c8   1Gi        RWO            rook-cephfs    21m
qytang-pvc-share   Bound    pvc-11406ed4-0ec9-4817-ad02-0fa8a43e993d   1Gi        RWX            rook-cephfs    25s

### 删除老的deploy, 应用新的share deploy (任何一个Master)
```shell script
kubectl delete deploy nginx-curl-ceph-dp
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/nginx-curl-ceph-dp-share.yaml

```

### 查看pod (任何一个Master)
[root@master01 ~]# kubectl get pods -l "app=nginx-curl-ceph-dp"
NAME                                  READY   STATUS    RESTARTS   AGE
nginx-curl-ceph-dp-656cc5fdc7-kfmxc   1/1     Running   0          50s
nginx-curl-ceph-dp-656cc5fdc7-pxplw   1/1     Running   0          50s
nginx-curl-ceph-dp-656cc5fdc7-tqg5c   1/1     Running   0          50s

### 进入容器创建文件index.html (任何一个Master)
[root@master01 ~]# kubectl exec -it nginx-curl-ceph-dp-656cc5fdc7-dtjgr -- /bin/bash
[root@nginx-curl-ceph-dp-656cc5fdc7-dtjgr /]# cd /usr/share/nginx/html/
[root@nginx-curl-ceph-dp-656cc5fdc7-dtjgr html]# vi index.html
<h1>share</h1>

### 进入其他容器也能看到share的index.html (任何一个Master)
[root@master01 ~]# kubectl exec -it nginx-curl-ceph-dp-656cc5fdc7-j9vfk -- /bin/bash
[root@nginx-curl-ceph-dp-656cc5fdc7-j9vfk /]# cd /usr/share/nginx/html/
[root@nginx-curl-ceph-dp-656cc5fdc7-j9vfk html]# cat index.html
<h1>share</h1>

----------------------------------注意此处切换设备--------------------------------------

### 网页访问https://nginx-ceph.qytangk8s.com/ (mgmtwin7)

----------------------------------注意此处切换设备--------------------------------------

### 应用资源配置清单 toolbox (任何一个Master)
```shell script
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/toolbox.yaml

````

### 进入容器, 执行命令 (任何一个Master)
```shell script
kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- bash

```

### 容器内查看ceph状态 (任何一个Master)
[root@rook-ceph-tools-55ffb568b4-ztl6k /]# ceph status
  cluster:
    id:     a4f97fe4-1f07-46c0-b696-1cc1d90cba93
    health: HEALTH_WARN
            clock skew detected on mon.c

  services:
    mon: 3 daemons, quorum a,b,c (age 37m)
    mgr: a(active, since 36m)
    mds: myfs:1 {0=myfs-a=up:active} 1 up:standby-replay
    osd: 9 osds: 9 up (since 33m), 9 in (since 33m)

  task status:
    scrub status:
        mds.myfs-a: idle
        mds.myfs-b: idle

  data:
    pools:   2 pools, 64 pgs
    objects: 30 objects, 160 KiB
    usage:   9.1 GiB used, 4.4 TiB / 4.4 TiB avail
    pgs:     64 active+clean

  io:
    client:   852 B/s rd, 1 op/s rd, 0 op/s wr

### 容器内查看ceph osd状态
[root@rook-ceph-tools-55ffb568b4-ztl6k /]# ceph osd status
+----+-----------------------+-------+-------+--------+---------+--------+---------+-----------+
| id |          host         |  used | avail | wr ops | wr data | rd ops | rd data |   state   |
+----+-----------------------+-------+-------+--------+---------+--------+---------+-----------+
| 0  | node02.qytanghost.com | 1030M |  498G |    0   |     0   |    0   |     0   | exists,up |
| 1  | node03.qytanghost.com | 1030M |  498G |    0   |     0   |    0   |     0   | exists,up |
| 2  | node01.qytanghost.com | 1030M |  498G |    0   |     0   |    0   |     0   | exists,up |
| 3  | node02.qytanghost.com | 1030M |  498G |    0   |     0   |    0   |     0   | exists,up |
| 4  | node03.qytanghost.com | 1030M |  498G |    0   |     0   |    0   |     0   | exists,up |
| 5  | node01.qytanghost.com | 1030M |  498G |    0   |     0   |    0   |     0   | exists,up |
| 6  | node02.qytanghost.com | 1030M |  498G |    0   |     0   |    2   |   106   | exists,up |
| 7  | node03.qytanghost.com | 1030M |  498G |    0   |     0   |    0   |     0   | exists,up |
| 8  | node01.qytanghost.com | 1030M |  498G |    0   |     0   |    0   |     0   | exists,up |
+----+-----------------------+-------+-------+--------+---------+--------+---------+-----------+

### Dashboard默认被安装, 只需要应用ingress资源配置清单即可 (任何一个Master)
```shell script
kubectl apply -f http://mgmtcentos.qytanghost.com/rook/ingress-dashboard.yaml

```

----------------------------------注意此处切换设备--------------------------------------

### 配置DNS (DNSCA)
```shell script
cat > /var/named/qytangk8s.com.zone <<'EOF'
$ORIGIN qytangk8s.com.
$TTL 600    ;   10 minutes
@       IN SOA  dnsca.qytangk8s.com. dnsadmin.qytangk8s.com. (
                                        2020090901      ; serial
                                        10800           ; refresh (3 hours)
                                        900             ; retry (15 minutes)
                                        604800          ; expire (1 week)
                                        86400           ; minimum (1 day)
                                        )
        NS      dnsca.qytangk8s.com.
$TTL 60    ;   1 minute
dnsca                        A   10.1.1.219
traefik                      A   10.1.1.10
qyt-lb-ds                    A   10.1.1.10
qyt-lb-dp                    A   10.1.1.10
k8sdashboard                 A   10.1.1.10
metricsserver                A   10.1.1.10
nginx-configmap              A   10.1.1.10
ceph-mgr-dashboard           A   10.1.1.10
EOF

systemctl restart named

```

----------------------------------注意此处切换设备--------------------------------------

### 登录Dashboard(mgmtwin7)
https://ceph-mgr-dashboard.qytangk8s.com/

用户:admin
密码:使用如下命令获取 (任何一个Master)
```shell
kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode && echo

```
